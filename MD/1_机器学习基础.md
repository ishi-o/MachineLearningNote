## 机器学习基础

### 数据集的概念

- 数据集(或样本集)是样本的集合，样本是特征的集合

- 通常，可以用**设计矩阵**来表示数据集，其中每一行是一条样本，每一列对应一个特征

- 根据用处的不同，数据集可以分为训练集、验证集、测试集

  - 训练集：用于训练模型的数据集

  - 验证集：用于初步评估模型的泛化能力，不直接调整模型参数，但可帮助开发者**调整超参数**

    每过一个训练周期，进行一次对验证集的计算

    当然，模型可以对训练集过拟合，肯定也有对验证集过拟合的情况

  - 测试集：模型定型后，用于检查它的最终泛化能力，必须保证计算过程不进行任何对模型的调整

    测试集必须是大量的、能反映真实环境复杂性的样本集

    否则，模型偷偷摸摸地背书，你还写在论文上有多高多高的准确率，那就是学术不端了

    在模型任何参数不变、输入的样本集也不变的情况下，结果理应是一样的，是可以完全复现的

- 数据生成过程(`Data Generating Process`，`DGP`)：指数据从其来源到被收集、存储的整个过程

- 数据集的假设：尽管上述训练集、验证集、测试集的用处不同，但通常遵循一些假设能使算法效果更好

  - 每个数据集中的不同样本是**相互独立**的
  - 不同数据集是同分布的，即采样来自相同的分布，这个潜在的分布被称为**数据生成分布**(通常不能被精确表示)

### 学习算法的概念

- 机器学习(`ML`)是实现人工智能的一种方法

- 机器学习常见的基础任务：

  - 分类任务：输出为一系列**离散的值**(表示不同的类别，可编号)，目标是预测某个**离散型变量**的分布
  - 回归任务：输出为一系列**确切的数值**，目标是预测某个**连续型变量**的分布
  - 聚类任务：与分类任务相似，但聚类任务依据分析数据本身特点而非标签来分组，实际是将整个样本集分为多个具有相似特征的样本的集合

- 一些更复杂的任务：

  - 结构化输出：
    - 转录任务：输入为一系列**非结构化**的数据，输出为离散的**有结构的文本标签**
    - 机器翻译任务：输入和输出均为有结构的**符号序列**，两种序列使用的语言不同
  - 异常检测：从输入中标记出异常、非典型的个体
  - 缺失值填补：补充样本中的已知缺失，其输出通常作为某种机器学习算法的输入
  - 去噪：去除样本中损坏的部分，这些损坏通常是非预期发生的

- 按结构特点可分为**传统机器学习**和**深度学习**(`DL`)

- 按算法特点可分为无监督学习、监督学习、半监督学习、强化学习

  - **监督学习**指样本集被人工贴上标签(`label`)，在模型得出预测值后和标签比较并反过来调整模型，即为有监督的学习过程

    监督学习中，一条样本拥有一个标签，所有样本的标签组成该数据集的标签向量$\boldsymbol y$

    监督学习常用于分类、回归任务

  - **无监督学习**指样本集没有提前贴上标签，完全靠分析(寻找隐藏的)数据集合的内部特点/结构来确定它们的标签，这类模型虽然没有样本集的指示，但仍然依赖梯度下降法

    无监督学习常用于聚类任务

  - **半监督学习**指样本集中的部分样本点拥有标签，模型通过对有标签数据的学习后完成对剩下无标签数据贴标签的任务

    相比无监督学习，它通过消耗少部分人力，得到更好的预测效果
  
  - **强化学习**的样本集同样没有标签，但它不倾向于分析样本集，而是**由反馈信号引导**(反馈信号由环境给出)，模型追求奖励最大化，最终得出全局的策略


### 模型评价标准

- 模型超参数：指模型的较高维度的由**人工调整**的参数

- 模型参数：指由模型自主学习并调整的学习函数的参数，例如权重、偏置等

- 模型容量：用于描述模型的复杂程度，数学定义是模型的假设空间(所有可选函数的集合)的大小

- 训练误差：指模型在训练集上的预测能力，模型在训练集上的预测能力越强，训练误差越小

- 泛化误差(测试误差)：指模型在经过样本集训练后，对**未知数据集**进行预测的能力

  对未知数据的预测结果越准确，称泛化误差越小，泛化能力强

- 过拟合：模型的训练误差很小，但泛化误差大，以至于显得像在对样本集死记硬背，称为过拟合

  原因：样本过少、样本噪音过大、模型容量过大

- 欠拟合：模型的训练误差很大，导致泛化误差也很大，连给定的样本集都没学明白

  原因：模型容量过小而无法学习复杂的问题

- 学习过程就是调整模型容量的过程，我们需要找到一个最优容量，使得泛化误差最小

- 没有免费午餐(`No Free Lunch`，`NFL`)定理：没有一个算法能在所有的问题上都优于其它算法

### 开发模型的过程

- 训练模型的目标：调整模型的参数以及超参数，使其泛化误差最小
- 数据准备：
  - 数据收集
  - 数据清洗：处理缺失、损坏、重复数据
  - 特征化：将数据整合为样本集，每条样本包括选定的特征
  - 数据划分：将数据集划分为训练集、验证集、测试集
- 设计模型：
  - 选择使用的模型，包括设定模型某层类型、模型层数等
  - 根据不同的任务选择合适的**损失函数**
  - 选择合适的**优化算法**
- 反复地训练模型、验证并调整超参数

### 损失函数的概念

- 无论是传统机器学习，还是深度学习，损失函数都是核心之一
- 损失函数用于表示模型的误差程度，模型以损失函数的值作为反馈调整其参数，根据不同的任务，模型应选择不同的损失函数
- 具体的损失函数将在后续具体的学习算法介绍中学习